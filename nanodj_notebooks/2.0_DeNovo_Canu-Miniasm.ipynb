{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *De novo* Canu and Miniasm assembly\n",
    "\n",
    "###### NOTE: This notebook has high memory and computational requirements\n",
    "\n",
    "Obtaining the assembled sequence of a complete genome is a complex multi-step task. For *De novo* assembly, the simplest elements of the hierarchy are the reads provided after the sequencing. The next level of hierarchy is the alignment of multiple reads without definite order (i.e. contigs). Finally, the top level of the hierarchy corresponds to the sum of two or more contigs where a (near) complete structure of the genome under study is obtained. Ideally, one expects to obtain a single fragment (contig) for each chromosome or a plasmid that is present in the genome. However, most of the times the assemblies are incomplete, especially when dealing with short reads that can be caused by the process of preparing the material or by the technological limitations. Specifically, when a repeat region is longer than the reads, this will create a single contig in the assembly with multiple connections. ONT provide long reads that can solve this problem albeit the per-base quality is still low (approximately 12-15% error rate)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *De novo* Canu assembly pipeline\n",
    "\n",
    "This notebook relies in the popular Canu pipeline (with Racon and Pilon to polish the assembly result) and Miniasm for *de novo* assembly of ONT reads. \n",
    "\n",
    "[Canu](https://github.com/marbl/canu) is a popular assembler based on the Celera Assembler that can reliably assemble complete microbial genomes and almost complete eukaryotic chromosomes. Canu has three stages: correction, trimming and assembly. Each stage can be executed independently or in series. Each of the three stages begins by identifying the overlaps between all the pairs of input reads, where they count k-mers in the reads, creating an indexed store of the overlays. From the input reads, the correction stage generates corrected reads. The trimming step trims non-compatible bases and detects fork adapters, chimeric sequences and other anomalies. The assembly stage builds an assembly graph and the contigs. Canu handles the repetitions probabilistically, by statistically filtering the repetitively induced overlays and retrospectively inspecting the graph for possible errors, thereby reducing the possibility of selecting a repetitive k-mer for the overlap. In this way, Canu performs multiple rounds of read and overlapping error correction.\n",
    "\n",
    "Canu substantially reduces coverage requirements with a low coverage hierarchical assembly. In this case, it is recommended to polish the assembly with short high-quality reads. Canu results are optimal with long-read coverages above 20x. \n",
    "\n",
    "Canu works with either FASTA or FASTQ files (compressed and uncompressed), but FASTQ format is needed to run some of the steps and complete the full pipeline. The help page is called with the \"canu -h\" command. These are the parameters needed for running Canu with our data:\n",
    "\n",
    "- **-p and -d**: Assembly files prefix and output directory. Both parameters can be the same and output directory doesn't have to exist before execution.\n",
    "\n",
    "- **-genomeSize**: The estimated genome size. In our case, 2.1 mbp so we write '2.1m'. We can put letter g for gbp or k for kbp as well.\n",
    "\n",
    "- **-nanopore-raw**: The path to our reads in FASTQ.\n",
    "\n",
    "Canu auto-detects available resources and will configure job sizes based on the resources and genome size that is being assembled. The following code uses advanced options like 'corMemory' and 'corThreads' to limit the resources in order to make Canu work on a resource-limited environment. These options also prevent Canu to stop the process because of a lack of computation power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "usage:   canu [-version] [-citation] \\\n",
      "              [-haplotype | -correct | -trim | -assemble | -trim-assemble] \\\n",
      "              [-s <assembly-specifications-file>] \\\n",
      "               -p <assembly-prefix> \\\n",
      "               -d <assembly-directory> \\\n",
      "               genomeSize=<number>[g|m|k] \\\n",
      "              [other-options] \\\n",
      "              [-haplotype{NAME} illumina.fastq.gz] \\\n",
      "              [-pacbio-raw |\n",
      "               -pacbio-corrected |\n",
      "               -nanopore-raw |\n",
      "               -nanopore-corrected] file1 file2 ...\n",
      "\n",
      "example: canu -d run1 -p godzilla genomeSize=1g -nanopore-raw reads/*.fasta.gz \n",
      "\n",
      "\n",
      "  To restrict canu to only a specific stage, use:\n",
      "    -haplotype     - generate haplotype-specific reads\n",
      "    -correct       - generate corrected reads\n",
      "    -trim          - generate trimmed reads\n",
      "    -assemble      - generate an assembly\n",
      "    -trim-assemble - generate trimmed reads and then assemble them\n",
      "\n",
      "  The assembly is computed in the -d <assembly-directory>, with output files named\n",
      "  using the -p <assembly-prefix>.  This directory is created if needed.  It is not\n",
      "  possible to run multiple assemblies in the same directory.\n",
      "\n",
      "  The genome size should be your best guess of the haploid genome size of what is being\n",
      "  assembled.  It is used primarily to estimate coverage in reads, NOT as the desired\n",
      "  assembly size.  Fractional values are allowed: '4.7m' equals '4700k' equals '4700000'\n",
      "\n",
      "  Some common options:\n",
      "    useGrid=string\n",
      "      - Run under grid control (true), locally (false), or set up for grid control\n",
      "        but don't submit any jobs (remote)\n",
      "    rawErrorRate=fraction-error\n",
      "      - The allowed difference in an overlap between two raw uncorrected reads.  For lower\n",
      "        quality reads, use a higher number.  The defaults are 0.300 for PacBio reads and\n",
      "        0.500 for Nanopore reads.\n",
      "    correctedErrorRate=fraction-error\n",
      "      - The allowed difference in an overlap between two corrected reads.  Assemblies of\n",
      "        low coverage or data with biological differences will benefit from a slight increase\n",
      "        in this.  Defaults are 0.045 for PacBio reads and 0.144 for Nanopore reads.\n",
      "    gridOptions=string\n",
      "      - Pass string to the command used to submit jobs to the grid.  Can be used to set\n",
      "        maximum run time limits.  Should NOT be used to set memory limits; Canu will do\n",
      "        that for you.\n",
      "    minReadLength=number\n",
      "      - Ignore reads shorter than 'number' bases long.  Default: 1000.\n",
      "    minOverlapLength=number\n",
      "      - Ignore read-to-read overlaps shorter than 'number' bases long.  Default: 500.\n",
      "  A full list of options can be printed with '-options'.  All options can be supplied in\n",
      "  an optional sepc file with the -s option.\n",
      "\n",
      "  For TrioCanu, haplotypes are specified with the -haplotype{NAME} option, with any\n",
      "  number of haplotype-specific Illumina read files after.  The {NAME} of each haplotype\n",
      "  is free text (but only letters and numbers, please).  For example:\n",
      "    -haplotypeNANNY nanny/*gz\n",
      "    -haplotypeBILLY billy1.fasta.gz billy2.fasta.gz\n",
      "\n",
      "  Reads can be either FASTA or FASTQ format, uncompressed, or compressed with gz, bz2 or xz.\n",
      "  Reads are specified by the technology they were generated with, and any processing performed:\n",
      "    -pacbio-raw         <files>      Reads are straight off the machine.\n",
      "    -pacbio-corrected   <files>      Reads have been corrected.\n",
      "    -nanopore-raw       <files>\n",
      "    -nanopore-corrected <files>\n",
      "\n",
      "Complete documentation at http://canu.readthedocs.org/en/latest/\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "execution_count": 1,
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "canu -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Canu snapshot v1.8 +44 changes (r9254 a50e26a75ffccc529bd944b7adb291e2b6e1c24b)\n",
      "--\n",
      "-- CITATIONS\n",
      "--\n",
      "-- Koren S, Walenz BP, Berlin K, Miller JR, Phillippy AM.\n",
      "-- Canu: scalable and accurate long-read assembly via adaptive k-mer weighting and repeat separation.\n",
      "-- Genome Res. 2017 May;27(5):722-736.\n",
      "-- http://doi.org/10.1101/gr.215087.116\n",
      "-- \n",
      "-- Koren S, Rhie A, Walenz BP, Dilthey AT, Bickhart DM, Kingan SB, Hiendleder S, Williams JL, Smith TPL, Phillippy AM.\n",
      "-- De novo assembly of haplotype-resolved genomes with trio binning.\n",
      "-- Nat Biotechnol. 2018\n",
      "-- https//doi.org/10.1038/nbt.4277\n",
      "-- \n",
      "-- Read and contig alignments during correction, consensus and GFA building use:\n",
      "--   Šošic M, Šikic M.\n",
      "--   Edlib: a C/C ++ library for fast, exact sequence alignment using edit distance.\n",
      "--   Bioinformatics. 2017 May 1;33(9):1394-1395.\n",
      "--   http://doi.org/10.1093/bioinformatics/btw753\n",
      "-- \n",
      "-- Overlaps are generated using:\n",
      "--   Berlin K, et al.\n",
      "--   Assembling large genomes with single-molecule sequencing and locality-sensitive hashing.\n",
      "--   Nat Biotechnol. 2015 Jun;33(6):623-30.\n",
      "--   http://doi.org/10.1038/nbt.3238\n",
      "-- \n",
      "--   Myers EW, et al.\n",
      "--   A Whole-Genome Assembly of Drosophila.\n",
      "--   Science. 2000 Mar 24;287(5461):2196-204.\n",
      "--   http://doi.org/10.1126/science.287.5461.2196\n",
      "-- \n",
      "-- Corrected read consensus sequences are generated using an algorithm derived from FALCON-sense:\n",
      "--   Chin CS, et al.\n",
      "--   Phased diploid genome assembly with single-molecule real-time sequencing.\n",
      "--   Nat Methods. 2016 Dec;13(12):1050-1054.\n",
      "--   http://doi.org/10.1038/nmeth.4035\n",
      "-- \n",
      "-- Contig consensus sequences are generated using an algorithm derived from pbdagcon:\n",
      "--   Chin CS, et al.\n",
      "--   Nonhybrid, finished microbial genome assemblies from long-read SMRT sequencing data.\n",
      "--   Nat Methods. 2013 Jun;10(6):563-9\n",
      "--   http://doi.org/10.1038/nmeth.2474\n",
      "-- \n",
      "-- CONFIGURE CANU\n",
      "--\n",
      "-- Detected Java(TM) Runtime Environment '1.8.0_181' (from 'java') with -d64 support.\n",
      "-- Detected gnuplot version '4.6 patchlevel 6   ' (from 'gnuplot') and image format 'png'.\n",
      "-- Detected 3 CPUs and 8 gigabytes of memory.\n",
      "-- Limited to 6 gigabytes from maxMemory option.\n",
      "-- No grid engine detected, grid disabled.\n",
      "--\n",
      "--                            (tag)Concurrency\n",
      "--                     (tag)Threads          |\n",
      "--            (tag)Memory         |          |\n",
      "--        (tag)         |         |          |     total usage     algorithm\n",
      "--        -------  ------  --------   --------  -----------------  -----------------------------\n",
      "-- Local: meryl      6 GB    3 CPUs x   1 job      6 GB    3 CPUs  (k-mer counting)\n",
      "-- Local: hap        6 GB    3 CPUs x   1 job      6 GB    3 CPUs  (read-to-haplotype assignment)\n",
      "-- Local: cormhap    6 GB    3 CPUs x   1 job      6 GB    3 CPUs  (overlap detection with mhap)\n",
      "-- Local: obtovl     4 GB    3 CPUs x   1 job      4 GB    3 CPUs  (overlap detection)\n",
      "-- Local: utgovl     4 GB    3 CPUs x   1 job      4 GB    3 CPUs  (overlap detection)\n",
      "-- Local: cor        2 GB    2 CPUs x   1 job      2 GB    2 CPUs  (read correction)\n",
      "-- Local: ovb        4 GB    1 CPU  x   1 job      4 GB    1 CPU   (overlap store bucketizer)\n",
      "-- Local: ovs        6 GB    1 CPU  x   1 job      6 GB    1 CPU   (overlap store sorting)\n",
      "-- Local: red        6 GB    3 CPUs x   1 job      6 GB    3 CPUs  (read error detection)\n",
      "-- Local: oea        4 GB    1 CPU  x   1 job      4 GB    1 CPU   (overlap error adjustment)\n",
      "-- Local: bat        6 GB    3 CPUs x   1 job      6 GB    3 CPUs  (contig construction with bogart)\n",
      "-- Local: cns      --- GB    3 CPUs x   1 job    --- GB    3 CPUs  (consensus)\n",
      "-- Local: gfa        6 GB    3 CPUs x   1 job      6 GB    3 CPUs  (GFA alignment and processing)\n",
      "--\n",
      "-- Found Nanopore uncorrected reads in the input files.\n",
      "--\n",
      "-- Generating assembly 'sample' in '/home/jovyan/notebooks/data/sample/canu_output'\n",
      "--\n",
      "-- Parameters:\n",
      "--\n",
      "--  genomeSize        2100000\n",
      "--\n",
      "--  Overlap Generation Limits:\n",
      "--    corOvlErrorRate 0.3200 ( 32.00%)\n",
      "--    obtOvlErrorRate 0.1200 ( 12.00%)\n",
      "--    utgOvlErrorRate 0.1200 ( 12.00%)\n",
      "--\n",
      "--  Overlap Processing Limits:\n",
      "--    corErrorRate    0.5000 ( 50.00%)\n",
      "--    obtErrorRate    0.1200 ( 12.00%)\n",
      "--    utgErrorRate    0.1200 ( 12.00%)\n",
      "--    cnsErrorRate    0.2000 ( 20.00%)\n",
      "--\n",
      "--\n",
      "-- BEGIN CORRECTION\n",
      "--\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 20:59:16 2018 with 2.245 GB free disk space\n",
      "\n",
      "    cd .\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/sqStoreCreate \\\n",
      "      -o ./sample.seqStore.BUILDING \\\n",
      "      -minlength 50 \\\n",
      "      ./sample.seqStore.ssi \\\n",
      "    > ./sample.seqStore.BUILDING.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 20:59:16 2018 (fast as lightning) with 2.236 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--\n",
      "-- In sequence store './sample.seqStore':\n",
      "--   Found 3604 reads.\n",
      "--   Found 34840031 bases (16.59 times coverage).\n",
      "--\n",
      "--   Read length histogram (one '*' equals 30.55 reads):\n",
      "--        0   4999   2139 **********************************************************************\n",
      "--     5000   9999    616 ********************\n",
      "--    10000  14999    283 *********\n",
      "--    15000  19999    164 *****\n",
      "--    20000  24999    101 ***\n",
      "--    25000  29999     66 **\n",
      "--    30000  34999     54 *\n",
      "--    35000  39999     29 \n",
      "--    40000  44999     26 \n",
      "--    45000  49999     18 \n",
      "--    50000  54999     13 \n",
      "--    55000  59999      7 \n",
      "--    60000  64999     15 \n",
      "--    65000  69999      6 \n",
      "--    70000  74999      7 \n",
      "--    75000  79999      2 \n",
      "--    80000  84999      6 \n",
      "--    85000  89999      5 \n",
      "--    90000  94999      4 \n",
      "--    95000  99999      3 \n",
      "--   100000 104999      1 \n",
      "--   105000 109999      4 \n",
      "--   110000 114999      3 \n",
      "--   115000 119999      2 \n",
      "--   120000 124999      2 \n",
      "--   125000 129999      1 \n",
      "--   130000 134999      2 \n",
      "--   135000 139999      1 \n",
      "--   140000 144999      2 \n",
      "--   145000 149999      1 \n",
      "--   150000 154999      1 \n",
      "--   155000 159999      3 \n",
      "--   160000 164999      1 \n",
      "--   165000 169999      0 \n",
      "--   170000 174999      0 \n",
      "--   175000 179999      3 \n",
      "--   180000 184999      1 \n",
      "--   185000 189999      2 \n",
      "--   190000 194999      2 \n",
      "--   195000 199999      0 \n",
      "--   200000 204999      1 \n",
      "--   205000 209999      0 \n",
      "--   210000 214999      0 \n",
      "--   215000 219999      0 \n",
      "--   220000 224999      0 \n",
      "--   225000 229999      0 \n",
      "--   230000 234999      0 \n",
      "--   235000 239999      1 \n",
      "--   240000 244999      0 \n",
      "--   245000 249999      0 \n",
      "--   250000 254999      0 \n",
      "--   255000 259999      1 \n",
      "--   260000 264999      0 \n",
      "--   265000 269999      0 \n",
      "--   270000 274999      0 \n",
      "--   275000 279999      1 \n",
      "--   280000 284999      0 \n",
      "--   285000 289999      1 \n",
      "--   290000 294999      0 \n",
      "--   295000 299999      0 \n",
      "--   300000 304999      0 \n",
      "--   305000 309999      0 \n",
      "--   310000 314999      0 \n",
      "--   315000 319999      0 \n",
      "--   320000 324999      0 \n",
      "--   325000 329999      0 \n",
      "--   330000 334999      0 \n",
      "--   335000 339999      0 \n",
      "--   340000 344999      0 \n",
      "--   345000 349999      1 \n",
      "--   350000 354999      0 \n",
      "--   355000 359999      0 \n",
      "--   360000 364999      0 \n",
      "--   365000 369999      0 \n",
      "--   370000 374999      0 \n",
      "--   375000 379999      1 \n",
      "--   380000 384999      0 \n",
      "--   385000 389999      1 \n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 20:59:16 2018 with 2.236 GB free disk space\n",
      "\n",
      "    cd correction/0-mercounts\n",
      "    ./meryl-configure.sh \\\n",
      "    > ./meryl-configure.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 20:59:17 2018 (one second) with 2.236 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--  segments   memory batches\n",
      "--  -------- -------- -------\n",
      "--        01  0.12 GB       1\n",
      "--\n",
      "--  For 3604 reads with 34840031 bases, limit to 1 batch.\n",
      "--  Will count kmers using 01 jobs, each using 2 GB and 3 threads.\n",
      "--\n",
      "-- Finished stage 'merylConfigure', reset canuIteration.\n",
      "--\n",
      "-- Running jobs.  First attempt out of 2.\n",
      "----------------------------------------\n",
      "-- Starting 'meryl' concurrent execution on Tue Nov 27 20:59:17 2018 with 2.236 GB free disk space (1 processes; 1 concurrently)\n",
      "\n",
      "    cd correction/0-mercounts\n",
      "    ./meryl-count.sh 1 > ./meryl-count.000001.out 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 20:59:21 2018 (4 seconds) with 2.089 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Found 1 Kmer counting (meryl) outputs.\n",
      "-- Finished stage 'cor-merylCountCheck', reset canuIteration.\n",
      "--\n",
      "-- Running jobs.  First attempt out of 2.\n",
      "----------------------------------------\n",
      "-- Starting 'meryl' concurrent execution on Tue Nov 27 20:59:21 2018 with 2.089 GB free disk space (1 processes; 1 concurrently)\n",
      "\n",
      "    cd correction/0-mercounts\n",
      "    ./meryl-process.sh 1 > ./meryl-process.000001.out 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 20:59:34 2018 (13 seconds) with 2.223 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--\n",
      "--  16-mers                                                                                           Fraction\n",
      "--    Occurrences   NumMers                                                                         Unique Total\n",
      "--       1-     1         0                                                                        0.0000 0.0000\n",
      "--       2-     2   1748994 ********************************************************************** 0.7725 0.5697\n",
      "--       3-     4    393824 ***************                                                        0.9089 0.7206\n",
      "--       5-     7     60200 **                                                                     0.9607 0.8022\n",
      "--       8-    11     25634 *                                                                      0.9766 0.8419\n",
      "--      12-    16     19377                                                                        0.9863 0.8787\n",
      "--      17-    22     11297                                                                        0.9942 0.9219\n",
      "--      23-    29      2275                                                                        0.9982 0.9508\n",
      "--      30-    37       719                                                                        0.9989 0.9581\n",
      "--      38-    46       450                                                                        0.9992 0.9618\n",
      "--      47-    56       280                                                                        0.9994 0.9648\n",
      "--      57-    67       227                                                                        0.9995 0.9670\n",
      "--      68-    79       160                                                                        0.9996 0.9693\n",
      "--      80-    92       147                                                                        0.9997 0.9712\n",
      "--      93-   106       106                                                                        0.9998 0.9733\n",
      "--     107-   121        87                                                                        0.9998 0.9749\n",
      "--     122-   137        66                                                                        0.9998 0.9765\n",
      "--     138-   154        69                                                                        0.9999 0.9780\n",
      "--     155-   172        43                                                                        0.9999 0.9795\n",
      "--     173-   191        24                                                                        0.9999 0.9806\n",
      "--     192-   211        20                                                                        0.9999 0.9813\n",
      "--     212-   232        20                                                                        0.9999 0.9820\n",
      "--     233-   254         7                                                                        0.9999 0.9827\n",
      "--     255-   277         7                                                                        0.9999 0.9830\n",
      "--     278-   301         7                                                                        0.9999 0.9833\n",
      "--     302-   326        14                                                                        0.9999 0.9837\n",
      "--     327-   352        14                                                                        1.0000 0.9844\n",
      "--     353-   379        11                                                                        1.0000 0.9852\n",
      "--     380-   407         8                                                                        1.0000 0.9858\n",
      "--     408-   436         9                                                                        1.0000 0.9863\n",
      "--     437-   466         9                                                                        1.0000 0.9869\n",
      "--     467-   497         2                                                                        1.0000 0.9876\n",
      "--     498-   529        12                                                                        1.0000 0.9877\n",
      "--     530-   562         5                                                                        1.0000 0.9888\n",
      "--     563-   596         7                                                                        1.0000 0.9892\n",
      "--     597-   631         5                                                                        1.0000 0.9899\n",
      "--     632-   667         5                                                                        1.0000 0.9904\n",
      "--     668-   704         2                                                                        1.0000 0.9909\n",
      "--     705-   742         1                                                                        1.0000 0.9911\n",
      "--     743-   781         3                                                                        1.0000 0.9913\n",
      "--     782-   821         1                                                                        1.0000 0.9916\n",
      "--\n",
      "--           0 (max occurrences)\n",
      "--     6140445 (total mers, non-unique)\n",
      "--     2264160 (distinct mers, non-unique)\n",
      "--           0 (unique mers)\n",
      "-- Finished stage 'meryl-process', reset canuIteration.\n",
      "--\n",
      "-- OVERLAPPER (mhap) (correction)\n",
      "--\n",
      "-- Set corMhapSensitivity=high based on read coverage of 16.\n",
      "--\n",
      "-- PARAMETERS: hashes=768, minMatches=2, threshold=0.78\n",
      "--\n",
      "-- Given 5.4 GB, can fit 8100 reads per block.\n",
      "-- For 2 blocks, set stride to 2 blocks.\n",
      "-- Logging partitioning to 'correction/1-overlapper/partitioning.log'.\n",
      "-- Configured 1 mhap precompute jobs.\n",
      "-- Configured 1 mhap overlap jobs.\n",
      "-- Finished stage 'cor-mhapConfigure', reset canuIteration.\n",
      "--\n",
      "-- Running jobs.  First attempt out of 2.\n",
      "----------------------------------------\n",
      "-- Starting 'cormhap' concurrent execution on Tue Nov 27 20:59:34 2018 with 2.223 GB free disk space (1 processes; 1 concurrently)\n",
      "\n",
      "    cd correction/1-overlapper\n",
      "    ./precompute.sh 1 > ./precompute.000001.out 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:05:26 2018 (352 seconds) with 2.135 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- All 1 mhap precompute jobs finished successfully.\n",
      "-- Finished stage 'cor-mhapPrecomputeCheck', reset canuIteration.\n",
      "--\n",
      "-- Running jobs.  First attempt out of 2.\n",
      "----------------------------------------\n",
      "-- Starting 'cormhap' concurrent execution on Tue Nov 27 21:05:27 2018 with 2.135 GB free disk space (1 processes; 1 concurrently)\n",
      "\n",
      "    cd correction/1-overlapper\n",
      "    ./mhap.sh 1 > ./mhap.000001.out 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:05:35 2018 (8 seconds) with 2.132 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Found 1 mhap overlap output files.\n",
      "-- Finished stage 'cor-mhapCheck', reset canuIteration.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:05:35 2018 with 2.132 GB free disk space\n",
      "\n",
      "    cd correction\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/ovStoreConfig \\\n",
      "     -S ../sample.seqStore \\\n",
      "     -M 4-6 \\\n",
      "     -L ./1-overlapper/ovljob.files \\\n",
      "     -create ./sample.ovlStore.config \\\n",
      "     > ./sample.ovlStore.config.txt \\\n",
      "    2> ./sample.ovlStore.config.err\n",
      "\n",
      "-- Finished on Tue Nov 27 21:05:35 2018 (fast as lightning) with 2.132 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--\n",
      "-- Creating overlap store correction/sample.ovlStore using:\n",
      "--      1 bucket\n",
      "--      2 slices\n",
      "--        using at most 1 GB memory each\n",
      "-- Finished stage 'cor-overlapStoreConfigure', reset canuIteration.\n",
      "--\n",
      "-- Running jobs.  First attempt out of 2.\n",
      "----------------------------------------\n",
      "-- Starting 'ovB' concurrent execution on Tue Nov 27 21:05:35 2018 with 2.132 GB free disk space (1 processes; 1 concurrently)\n",
      "\n",
      "    cd correction/sample.ovlStore.BUILDING\n",
      "    ./scripts/1-bucketize.sh 1 > ./logs/1-bucketize.000001.out 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:05:35 2018 (fast as lightning) with 2.127 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Overlap store bucketizer finished.\n",
      "-- Finished stage 'cor-overlapStoreBucketizerCheck', reset canuIteration.\n",
      "--\n",
      "-- Running jobs.  First attempt out of 2.\n",
      "----------------------------------------\n",
      "-- Starting 'ovS' concurrent execution on Tue Nov 27 21:05:35 2018 with 2.127 GB free disk space (2 processes; 1 concurrently)\n",
      "\n",
      "    cd correction/sample.ovlStore.BUILDING\n",
      "    ./scripts/2-sort.sh 1 > ./logs/2-sort.000001.out 2>&1\n",
      "    ./scripts/2-sort.sh 2 > ./logs/2-sort.000002.out 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:05:36 2018 (one second) with 2.1 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Overlap store sorter finished.\n",
      "-- Finished stage 'cor-overlapStoreSorterCheck', reset canuIteration.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:05:36 2018 with 2.1 GB free disk space\n",
      "\n",
      "    cd correction\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/ovStoreIndexer \\\n",
      "      -O  ./sample.ovlStore.BUILDING \\\n",
      "      -S ../sample.seqStore \\\n",
      "      -C  ./sample.ovlStore.config \\\n",
      "      -delete \\\n",
      "    > ./sample.ovlStore.BUILDING.index.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:05:36 2018 (in the blink of an eye) with 2.108 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Checking store.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:05:36 2018 with 2.108 GB free disk space\n",
      "\n",
      "    cd correction\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/ovStoreDump \\\n",
      "     -S ../sample.seqStore \\\n",
      "     -O  ./sample.ovlStore \\\n",
      "     -counts \\\n",
      "     > ./sample.ovlStore/counts.dat 2> ./sample.ovlStore/counts.err\n",
      "\n",
      "-- Finished on Tue Nov 27 21:05:36 2018 (lickety-split) with 2.108 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--\n",
      "-- Overlap store 'correction/sample.ovlStore' successfully constructed.\n",
      "-- Found 341246 overlaps for 2358 reads; 1246 reads have no overlaps.\n",
      "--\n",
      "--\n",
      "-- Purged 0.091 GB in 3 overlap output files.\n",
      "-- Finished stage 'cor-createOverlapStore', reset canuIteration.\n",
      "-- Set corMinCoverage=0 based on read coverage of 16.\n",
      "-- Global filter scores will be estimated.\n",
      "-- Computing correction layouts.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:05:36 2018 with 2.2 GB free disk space\n",
      "\n",
      "    cd correction\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/generateCorrectionLayouts \\\n",
      "      -S ../sample.seqStore \\\n",
      "      -O  ./sample.ovlStore \\\n",
      "      -C  ./sample.corStore.WORKING \\\n",
      "      -eC 80 \\\n",
      "    > ./sample.corStore.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:05:36 2018 (furiously fast) with 2.197 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Finished stage 'cor-buildCorrectionLayoutsConfigure', reset canuIteration.\n",
      "-- Computing correction layouts.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:05:36 2018 with 2.197 GB free disk space\n",
      "\n",
      "    cd correction/2-correction\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/filterCorrectionLayouts \\\n",
      "      -S  ../../sample.seqStore \\\n",
      "      -C     ../sample.corStore \\\n",
      "      -R      ./sample.readsToCorrect.WORKING \\\n",
      "      -cc 0 \\\n",
      "      -cl 50 \\\n",
      "      -g  2100000 \\\n",
      "      -c  40 \\\n",
      "    > ./sample.readsToCorrect.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:05:36 2018 (fast as lightning) with 2.197 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--                             original      original\n",
      "--                            raw reads     raw reads\n",
      "--   category                w/overlaps  w/o/overlaps\n",
      "--   -------------------- ------------- -------------\n",
      "--   Number of Reads               2320          1284\n",
      "--   Number of Bases           18949600         59604\n",
      "--   Coverage                     9.024         0.028\n",
      "--   Median                        2277             0\n",
      "--   Mean                          8167            46\n",
      "--   N50                          30997          3024\n",
      "--   Minimum                         50             0\n",
      "--   Maximum                     388351          7195\n",
      "--   \n",
      "--                                        --------corrected---------  ----------rescued----------\n",
      "--                             evidence                     expected                     expected\n",
      "--   category                     reads            raw     corrected            raw     corrected\n",
      "--   -------------------- -------------  ------------- -------------  ------------- -------------\n",
      "--   Number of Reads               2358           2319          2319              0             0\n",
      "--   Number of Bases           19009204       18572201      16458008              0             0\n",
      "--   Coverage                     9.052          8.844         7.837          0.000         0.000\n",
      "--   Median                        2249           2270          1519              0             0\n",
      "--   Mean                          8061           8008          7097              0             0\n",
      "--   N50                          30977          29633         32724              0             0\n",
      "--   Minimum                         50             50             4              0             0\n",
      "--   Maximum                     388351         388351        319526              0             0\n",
      "--   \n",
      "--                        --------uncorrected--------\n",
      "--                                           expected\n",
      "--   category                       raw     corrected\n",
      "--   -------------------- ------------- -------------\n",
      "--   Number of Reads               1285          1285\n",
      "--   Number of Bases             437003        320859\n",
      "--   Coverage                     0.208         0.153\n",
      "--   Median                           0             0\n",
      "--   Mean                           340           249\n",
      "--   N50                              0             0\n",
      "--   Minimum                          0             0\n",
      "--   Maximum                     377399        320859\n",
      "--   \n",
      "--   Maximum Memory          4028799956\n",
      "-- Finished stage 'cor-filterCorrectionLayouts', reset canuIteration.\n",
      "-- Using overlaps no worse than 0.5 fraction error for correcting reads (from corErrorRate parameter).\n",
      "-- Finished stage 'cor-generateCorrectedReadsConfigure', reset canuIteration.\n",
      "--\n",
      "-- Running jobs.  First attempt out of 2.\n",
      "----------------------------------------\n",
      "-- Starting 'cor' concurrent execution on Tue Nov 27 21:05:36 2018 with 2.197 GB free disk space (1 processes; 1 concurrently)\n",
      "\n",
      "    cd correction/2-correction\n",
      "    ./correctReads.sh 1 > ./correctReads.000001.out 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:16:43 2018 (667 seconds) with 2.16 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Found 1 read correction output files.\n",
      "-- Finished stage 'cor-generateCorrectedReadsCheck', reset canuIteration.\n",
      "-- Found 1 read correction output files.\n",
      "-- Finished stage 'cor-generateCorrectedReadsCheck', reset canuIteration.\n",
      "--\n",
      "-- Loading corrected reads into corStore and seqStore.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:16:43 2018 with 2.16 GB free disk space\n",
      "\n",
      "    cd correction\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/loadCorrectedReads \\\n",
      "      -S ../sample.seqStore \\\n",
      "      -C ./sample.corStore \\\n",
      "      -L ./2-correction/corjob.files \\\n",
      "    >  ./sample.loadCorrectedReads.log \\\n",
      "    2> ./sample.loadCorrectedReads.err\n",
      "\n",
      "-- Finished on Tue Nov 27 21:16:43 2018 (in the blink of an eye) with 2.151 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--\n",
      "-- In sequence store './sample.seqStore':\n",
      "--   Found 2318 reads.\n",
      "--   Found 18367583 bases (8.74 times coverage).\n",
      "--\n",
      "--   Read length histogram (one '*' equals 23.44 reads):\n",
      "--        0   4999   1641 **********************************************************************\n",
      "--     5000   9999    323 *************\n",
      "--    10000  14999    135 *****\n",
      "--    15000  19999     68 **\n",
      "--    20000  24999     28 *\n",
      "--    25000  29999     25 *\n",
      "--    30000  34999     20 \n",
      "--    35000  39999      7 \n",
      "--    40000  44999      9 \n",
      "--    45000  49999      5 \n",
      "--    50000  54999      3 \n",
      "--    55000  59999      1 \n",
      "--    60000  64999      5 \n",
      "--    65000  69999      2 \n",
      "--    70000  74999      3 \n",
      "--    75000  79999      2 \n",
      "--    80000  84999      3 \n",
      "--    85000  89999      2 \n",
      "--    90000  94999      0 \n",
      "--    95000  99999      2 \n",
      "--   100000 104999      1 \n",
      "--   105000 109999      3 \n",
      "--   110000 114999      2 \n",
      "--   115000 119999      1 \n",
      "--   120000 124999      1 \n",
      "--   125000 129999      1 \n",
      "--   130000 134999      2 \n",
      "--   135000 139999      1 \n",
      "--   140000 144999      2 \n",
      "--   145000 149999      1 \n",
      "--   150000 154999      0 \n",
      "--   155000 159999      3 \n",
      "--   160000 164999      1 \n",
      "--   165000 169999      0 \n",
      "--   170000 174999      0 \n",
      "--   175000 179999      3 \n",
      "--   180000 184999      1 \n",
      "--   185000 189999      2 \n",
      "--   190000 194999      2 \n",
      "--   195000 199999      0 \n",
      "--   200000 204999      1 \n",
      "--   205000 209999      0 \n",
      "--   210000 214999      0 \n",
      "--   215000 219999      0 \n",
      "--   220000 224999      0 \n",
      "--   225000 229999      0 \n",
      "--   230000 234999      0 \n",
      "--   235000 239999      1 \n",
      "--   240000 244999      0 \n",
      "--   245000 249999      0 \n",
      "--   250000 254999      0 \n",
      "--   255000 259999      1 \n",
      "--   260000 264999      0 \n",
      "--   265000 269999      0 \n",
      "--   270000 274999      0 \n",
      "--   275000 279999      1 \n",
      "--   280000 284999      0 \n",
      "--   285000 289999      1 \n",
      "--   290000 294999      0 \n",
      "--   295000 299999      0 \n",
      "--   300000 304999      0 \n",
      "--   305000 309999      0 \n",
      "--   310000 314999      0 \n",
      "--   315000 319999      0 \n",
      "--   320000 324999      0 \n",
      "--   325000 329999      0 \n",
      "--   330000 334999      0 \n",
      "--   335000 339999      0 \n",
      "--   340000 344999      0 \n",
      "--   345000 349999      1 \n",
      "--   350000 354999      0 \n",
      "--   355000 359999      0 \n",
      "--   360000 364999      0 \n",
      "--   365000 369999      0 \n",
      "--   370000 374999      0 \n",
      "--   375000 379999      0 \n",
      "--   380000 384999      0 \n",
      "--   385000 389999      1 \n",
      "--\n",
      "-- Purging correctReads output after loading into stores.\n",
      "-- Purged 1 .cns outputs.\n",
      "-- Purged 2 .out job log outputs.\n",
      "--\n",
      "-- Purging overlaps used for correction.\n",
      "-- Finished stage 'cor-loadCorrectedReads', reset canuIteration.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:16:43 2018 with 2.211 GB free disk space\n",
      "\n",
      "    cd .\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/sqStoreDumpFASTQ \\\n",
      "      -corrected \\\n",
      "      -S ./sample.seqStore \\\n",
      "      -o ./sample.correctedReads.gz \\\n",
      "      -fasta \\\n",
      "      -nolibname \\\n",
      "    > sample.correctedReads.fasta.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:16:44 2018 (one second) with 2.205 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--\n",
      "-- Corrected reads saved in 'sample.correctedReads.fasta.gz'.\n",
      "-- Finished stage 'cor-dumpCorrectedReads', reset canuIteration.\n",
      "--\n",
      "--\n",
      "-- BEGIN TRIMMING\n",
      "--\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:16:44 2018 with 2.205 GB free disk space\n",
      "\n",
      "    cd trimming/0-mercounts\n",
      "    ./meryl-configure.sh \\\n",
      "    > ./meryl-configure.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:16:44 2018 (fast as lightning) with 2.205 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--  segments   memory batches\n",
      "--  -------- -------- -------\n",
      "--        01  0.12 GB       1\n",
      "--\n",
      "--  For 2318 reads with 18367583 bases, limit to 1 batch.\n",
      "--  Will count kmers using 01 jobs, each using 2 GB and 3 threads.\n",
      "--\n",
      "-- Finished stage 'merylConfigure', reset canuIteration.\n",
      "--\n",
      "-- Running jobs.  First attempt out of 2.\n",
      "----------------------------------------\n",
      "-- Starting 'meryl' concurrent execution on Tue Nov 27 21:16:44 2018 with 2.205 GB free disk space (1 processes; 1 concurrently)\n",
      "\n",
      "    cd trimming/0-mercounts\n",
      "    ./meryl-count.sh 1 > ./meryl-count.000001.out 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:16:46 2018 (2 seconds) with 2.109 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Found 1 Kmer counting (meryl) outputs.\n",
      "-- Finished stage 'obt-merylCountCheck', reset canuIteration.\n",
      "--\n",
      "-- Running jobs.  First attempt out of 2.\n",
      "----------------------------------------\n",
      "-- Starting 'meryl' concurrent execution on Tue Nov 27 21:16:46 2018 with 2.109 GB free disk space (1 processes; 1 concurrently)\n",
      "\n",
      "    cd trimming/0-mercounts\n",
      "    ./meryl-process.sh 1 > ./meryl-process.000001.out 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:16:59 2018 (13 seconds) with 2.2 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--\n",
      "--  22-mers                                                                                           Fraction\n",
      "--    Occurrences   NumMers                                                                         Unique Total\n",
      "--       1-     1         0                                                                        0.0000 0.0000\n",
      "--       2-     2    283705 ***************************************************************        0.3887 0.1578\n",
      "--       3-     4    312953 ********************************************************************** 0.6720 0.3304\n",
      "--       5-     7     75805 ****************                                                       0.8802 0.5122\n",
      "--       8-    11      7719 *                                                                      0.9255 0.5717\n",
      "--      12-    16      6043 *                                                                      0.9334 0.5883\n",
      "--      17-    22      9453 **                                                                     0.9423 0.6158\n",
      "--      23-    29      7525 *                                                                      0.9543 0.6645\n",
      "--      30-    37     21246 ****                                                                   0.9647 0.7214\n",
      "--      38-    46      4987 *                                                                      0.9956 0.9411\n",
      "--      47-    56       112                                                                        0.9993 0.9706\n",
      "--      57-    67        86                                                                        0.9994 0.9722\n",
      "--      68-    79        91                                                                        0.9996 0.9737\n",
      "--      80-    92        59                                                                        0.9997 0.9755\n",
      "--      93-   106        21                                                                        0.9998 0.9769\n",
      "--     107-   121        12                                                                        0.9998 0.9774\n",
      "--     122-   137        22                                                                        0.9998 0.9778\n",
      "--     138-   154         7                                                                        0.9998 0.9786\n",
      "--     155-   172         7                                                                        0.9998 0.9789\n",
      "--     173-   191         5                                                                        0.9998 0.9792\n",
      "--     192-   211         0                                                                        0.0000 0.0000\n",
      "--     212-   232         4                                                                        0.9999 0.9794\n",
      "--     233-   254         2                                                                        0.9999 0.9797\n",
      "--     255-   277         0                                                                        0.0000 0.0000\n",
      "--     278-   301         6                                                                        0.9999 0.9798\n",
      "--     302-   326         8                                                                        0.9999 0.9803\n",
      "--     327-   352        11                                                                        0.9999 0.9810\n",
      "--     353-   379         8                                                                        0.9999 0.9821\n",
      "--     380-   407        10                                                                        0.9999 0.9829\n",
      "--     408-   436         5                                                                        0.9999 0.9840\n",
      "--     437-   466         4                                                                        0.9999 0.9846\n",
      "--     467-   497         6                                                                        0.9999 0.9851\n",
      "--     498-   529         5                                                                        0.9999 0.9859\n",
      "--     530-   562         2                                                                        0.9999 0.9866\n",
      "--     563-   596         0                                                                        0.0000 0.0000\n",
      "--     597-   631         5                                                                        0.9999 0.9870\n",
      "--     632-   667        12                                                                        1.0000 0.9878\n",
      "--     668-   704         2                                                                        1.0000 0.9900\n",
      "--     705-   742         4                                                                        1.0000 0.9904\n",
      "--     743-   781         5                                                                        1.0000 0.9912\n",
      "--\n",
      "--           0 (max occurrences)\n",
      "--     3595515 (total mers, non-unique)\n",
      "--      729967 (distinct mers, non-unique)\n",
      "--           0 (unique mers)\n",
      "-- Finished stage 'meryl-process', reset canuIteration.\n",
      "--\n",
      "-- OVERLAPPER (normal) (trimming) erate=0.12\n",
      "--\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:16:59 2018 with 2.199 GB free disk space\n",
      "\n",
      "    cd trimming/1-overlapper\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/overlapInCorePartition \\\n",
      "     -S  ../../sample.seqStore \\\n",
      "     -hl 80000000 \\\n",
      "     -rl 1000000000 \\\n",
      "     -ol 50 \\\n",
      "     -o  ./sample.partition \\\n",
      "    > ./sample.partition.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:16:59 2018 (in the blink of an eye) with 2.199 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--\n",
      "-- Configured 1 overlapInCore jobs.\n",
      "-- Finished stage 'obt-overlapConfigure', reset canuIteration.\n",
      "--\n",
      "-- Running jobs.  First attempt out of 2.\n",
      "----------------------------------------\n",
      "-- Starting 'obtovl' concurrent execution on Tue Nov 27 21:16:59 2018 with 2.199 GB free disk space (1 processes; 1 concurrently)\n",
      "\n",
      "    cd trimming/1-overlapper\n",
      "    ./overlap.sh 1 > ./overlap.000001.out 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:10 2018 (71 seconds) with 2.197 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Found 1 overlapInCore output files.\n",
      "--\n",
      "-- overlapInCore compute 'trimming/1-overlapper':\n",
      "--   kmer hits\n",
      "--     with no overlap            62784       62784 +- 0\n",
      "--     with an overlap           133810      133810 +- 0\n",
      "--\n",
      "--   overlaps                    133801      133801 +- 0\n",
      "--     contained                      0           0 +- 0\n",
      "--     dovetail                       0           0 +- 0\n",
      "--\n",
      "--   overlaps rejected\n",
      "--     multiple per pair              0           0 +- 0\n",
      "--     bad short window               0           0 +- 0\n",
      "--     bad long window                0           0 +- 0\n",
      "-- Finished stage 'obt-overlapCheck', reset canuIteration.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:10 2018 with 2.197 GB free disk space\n",
      "\n",
      "    cd trimming\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/ovStoreConfig \\\n",
      "     -S ../sample.seqStore \\\n",
      "     -M 1 \\\n",
      "     -L ./1-overlapper/ovljob.files \\\n",
      "     -create ./sample.ovlStore.config \\\n",
      "     > ./sample.ovlStore.config.txt \\\n",
      "    2> ./sample.ovlStore.config.err\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:10 2018 (lickety-split) with 2.197 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--\n",
      "-- Creating overlap store trimming/sample.ovlStore using:\n",
      "--      1 bucket\n",
      "--      2 slices\n",
      "--        using at most 1 GB memory each\n",
      "-- Finished stage 'obt-overlapStoreConfigure', reset canuIteration.\n",
      "--\n",
      "-- Running jobs.  First attempt out of 2.\n",
      "----------------------------------------\n",
      "-- Starting 'ovB' concurrent execution on Tue Nov 27 21:18:10 2018 with 2.197 GB free disk space (1 processes; 1 concurrently)\n",
      "\n",
      "    cd trimming/sample.ovlStore.BUILDING\n",
      "    ./scripts/1-bucketize.sh 1 > ./logs/1-bucketize.000001.out 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:10 2018 (furiously fast) with 2.194 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Overlap store bucketizer finished.\n",
      "-- Finished stage 'obt-overlapStoreBucketizerCheck', reset canuIteration.\n",
      "--\n",
      "-- Running jobs.  First attempt out of 2.\n",
      "----------------------------------------\n",
      "-- Starting 'ovS' concurrent execution on Tue Nov 27 21:18:10 2018 with 2.194 GB free disk space (2 processes; 1 concurrently)\n",
      "\n",
      "    cd trimming/sample.ovlStore.BUILDING\n",
      "    ./scripts/2-sort.sh 1 > ./logs/2-sort.000001.out 2>&1\n",
      "    ./scripts/2-sort.sh 2 > ./logs/2-sort.000002.out 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:11 2018 (one second) with 2.179 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Overlap store sorter finished.\n",
      "-- Finished stage 'obt-overlapStoreSorterCheck', reset canuIteration.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:11 2018 with 2.179 GB free disk space\n",
      "\n",
      "    cd trimming\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/ovStoreIndexer \\\n",
      "      -O  ./sample.ovlStore.BUILDING \\\n",
      "      -S ../sample.seqStore \\\n",
      "      -C  ./sample.ovlStore.config \\\n",
      "      -delete \\\n",
      "    > ./sample.ovlStore.BUILDING.index.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:11 2018 (lickety-split) with 2.184 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Checking store.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:11 2018 with 2.184 GB free disk space\n",
      "\n",
      "    cd trimming\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/ovStoreDump \\\n",
      "     -S ../sample.seqStore \\\n",
      "     -O  ./sample.ovlStore \\\n",
      "     -counts \\\n",
      "     > ./sample.ovlStore/counts.dat 2> ./sample.ovlStore/counts.err\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:11 2018 (fast as lightning) with 2.184 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--\n",
      "-- Overlap store 'trimming/sample.ovlStore' successfully constructed.\n",
      "-- Found 267620 overlaps for 1525 reads; 2079 reads have no overlaps.\n",
      "--\n",
      "--\n",
      "-- Purged 0.001 GB in 3 overlap output files.\n",
      "-- Finished stage 'obt-createOverlapStore', reset canuIteration.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:11 2018 with 2.186 GB free disk space\n",
      "\n",
      "    cd trimming/3-overlapbasedtrimming\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/trimReads \\\n",
      "      -S  ../../sample.seqStore \\\n",
      "      -O  ../sample.ovlStore \\\n",
      "      -Co ./sample.1.trimReads.clear \\\n",
      "      -e  0.12 \\\n",
      "      -minlength 50 \\\n",
      "      -ol 1 \\\n",
      "      -oc 1 \\\n",
      "      -o  ./sample.1.trimReads \\\n",
      "    >     ./sample.1.trimReads.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:11 2018 (in the blink of an eye) with 2.186 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--  PARAMETERS:\n",
      "--  ----------\n",
      "--       50    (reads trimmed below this many bases are deleted)\n",
      "--   0.1200    (use overlaps at or below this fraction error)\n",
      "--        1    (break region if overlap is less than this long, for 'largest covered' algorithm)\n",
      "--        1    (break region if overlap coverage is less than this many read, for 'largest covered' algorithm)\n",
      "--  \n",
      "--  INPUT READS:\n",
      "--  -----------\n",
      "--    3604 reads     18367583 bases (reads processed)\n",
      "--       0 reads            0 bases (reads not processed, previously deleted)\n",
      "--       0 reads            0 bases (reads not processed, in a library where trimming isn't allowed)\n",
      "--  \n",
      "--  OUTPUT READS:\n",
      "--  ------------\n",
      "--    1505 reads      3997099 bases (trimmed reads output)\n",
      "--      20 reads        86454 bases (reads with no change, kept as is)\n",
      "--    2079 reads      8730597 bases (reads with no overlaps, deleted)\n",
      "--       0 reads            0 bases (reads with short trimmed length, deleted)\n",
      "--  \n",
      "--  TRIMMING DETAILS:\n",
      "--  ----------------\n",
      "--    1238 reads      2710668 bases (bases trimmed from the 5' end of a read)\n",
      "--    1436 reads      2842765 bases (bases trimmed from the 3' end of a read)\n",
      "-- Finished stage 'obt-trimReads', reset canuIteration.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:11 2018 with 2.186 GB free disk space\n",
      "\n",
      "    cd trimming/3-overlapbasedtrimming\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/splitReads \\\n",
      "      -S  ../../sample.seqStore \\\n",
      "      -O  ../sample.ovlStore \\\n",
      "      -Ci ./sample.1.trimReads.clear \\\n",
      "      -Co ./sample.2.splitReads.clear \\\n",
      "      -e  0.12 \\\n",
      "      -minlength 50 \\\n",
      "      -o  ./sample.2.splitReads \\\n",
      "    >     ./sample.2.splitReads.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:11 2018 (in the blink of an eye) with 2.186 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--  PARAMETERS:\n",
      "--  ----------\n",
      "--       50    (reads trimmed below this many bases are deleted)\n",
      "--   0.1200    (use overlaps at or below this fraction error)\n",
      "--  INPUT READS:\n",
      "--  -----------\n",
      "--    1525 reads      9636986 bases (reads processed)\n",
      "--    2079 reads      8730597 bases (reads not processed, previously deleted)\n",
      "--       0 reads            0 bases (reads not processed, in a library where trimming isn't allowed)\n",
      "--  \n",
      "--  PROCESSED:\n",
      "--  --------\n",
      "--       0 reads            0 bases (no overlaps)\n",
      "--     156 reads       922509 bases (no coverage after adjusting for trimming done already)\n",
      "--       0 reads            0 bases (processed for chimera)\n",
      "--       0 reads            0 bases (processed for spur)\n",
      "--    1369 reads      8714477 bases (processed for subreads)\n",
      "--  \n",
      "--  READS WITH SIGNALS:\n",
      "--  ------------------\n",
      "--       0 reads            0 signals (number of 5' spur signal)\n",
      "--       0 reads            0 signals (number of 3' spur signal)\n",
      "--       0 reads            0 signals (number of chimera signal)\n",
      "--       0 reads            0 signals (number of subread signal)\n",
      "--  \n",
      "--  SIGNALS:\n",
      "--  -------\n",
      "--       0 reads            0 bases (size of 5' spur signal)\n",
      "--       0 reads            0 bases (size of 3' spur signal)\n",
      "--       0 reads            0 bases (size of chimera signal)\n",
      "--       0 reads            0 bases (size of subread signal)\n",
      "--  \n",
      "--  TRIMMING:\n",
      "--  --------\n",
      "--       0 reads            0 bases (trimmed from the 5' end of the read)\n",
      "--       0 reads            0 bases (trimmed from the 3' end of the read)\n",
      "-- Finished stage 'obt-splitReads', reset canuIteration.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:11 2018 with 2.186 GB free disk space\n",
      "\n",
      "    cd trimming/3-overlapbasedtrimming\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/loadTrimmedReads \\\n",
      "      -S ../../sample.seqStore \\\n",
      "      -c ./sample.2.splitReads.clear \\\n",
      "    > ./sample.loadtrimmedReads.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:11 2018 (in the blink of an eye) with 2.186 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--\n",
      "-- In sequence store './sample.seqStore':\n",
      "--   Found 1525 reads.\n",
      "--   Found 4083553 bases (1.94 times coverage).\n",
      "--\n",
      "--   Read length histogram (one '*' equals 10.77 reads):\n",
      "--        0    999    754 **********************************************************************\n",
      "--     1000   1999    253 ***********************\n",
      "--     2000   2999    147 *************\n",
      "--     3000   3999     78 *******\n",
      "--     4000   4999     53 ****\n",
      "--     5000   5999     46 ****\n",
      "--     6000   6999     37 ***\n",
      "--     7000   7999     15 *\n",
      "--     8000   8999     20 *\n",
      "--     9000   9999     25 **\n",
      "--    10000  10999     14 *\n",
      "--    11000  11999     10 \n",
      "--    12000  12999     10 \n",
      "--    13000  13999     14 *\n",
      "--    14000  14999      8 \n",
      "--    15000  15999      3 \n",
      "--    16000  16999      6 \n",
      "--    17000  17999      2 \n",
      "--    18000  18999      2 \n",
      "--    19000  19999      6 \n",
      "--    20000  20999      3 \n",
      "--    21000  21999      2 \n",
      "--    22000  22999      1 \n",
      "--    23000  23999      0 \n",
      "--    24000  24999      2 \n",
      "--    25000  25999      5 \n",
      "--    26000  26999      1 \n",
      "--    27000  27999      2 \n",
      "--    28000  28999      1 \n",
      "--    29000  29999      0 \n",
      "--    30000  30999      0 \n",
      "--    31000  31999      3 \n",
      "--    32000  32999      0 \n",
      "--    33000  33999      0 \n",
      "--    34000  34999      2 \n",
      "--\n",
      "-- Purging overlaps used for trimming.\n",
      "-- Finished stage 'obt-dumpReads', reset canuIteration.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:11 2018 with 2.199 GB free disk space\n",
      "\n",
      "    cd .\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/sqStoreDumpFASTQ \\\n",
      "      -trimmed \\\n",
      "      -S ./sample.seqStore \\\n",
      "      -o ./sample.trimmedReads.gz \\\n",
      "      -fasta \\\n",
      "      -nolibname \\\n",
      "    > ./sample.trimmedReads.fasta.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:11 2018 (like a bat out of hell) with 2.198 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--\n",
      "-- Trimmed reads saved in 'sample.trimmedReads.fasta.gz'.\n",
      "-- Finished stage 'cor-dumpTrimmedReads', reset canuIteration.\n",
      "--\n",
      "--\n",
      "-- BEGIN ASSEMBLY\n",
      "--\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:11 2018 with 2.198 GB free disk space\n",
      "\n",
      "    cd unitigging/0-mercounts\n",
      "    ./meryl-configure.sh \\\n",
      "    > ./meryl-configure.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:11 2018 (in the blink of an eye) with 2.198 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--  segments   memory batches\n",
      "--  -------- -------- -------\n",
      "--        01  0.06 GB       1\n",
      "--\n",
      "--  For 1525 reads with 4083553 bases, limit to 1 batch.\n",
      "--  Will count kmers using 01 jobs, each using 2 GB and 3 threads.\n",
      "--\n",
      "-- Finished stage 'merylConfigure', reset canuIteration.\n",
      "--\n",
      "-- Running jobs.  First attempt out of 2.\n",
      "----------------------------------------\n",
      "-- Starting 'meryl' concurrent execution on Tue Nov 27 21:18:11 2018 with 2.198 GB free disk space (1 processes; 1 concurrently)\n",
      "\n",
      "    cd unitigging/0-mercounts\n",
      "    ./meryl-count.sh 1 > ./meryl-count.000001.out 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:13 2018 (2 seconds) with 2.186 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Found 1 Kmer counting (meryl) outputs.\n",
      "-- Finished stage 'utg-merylCountCheck', reset canuIteration.\n",
      "--\n",
      "-- Running jobs.  First attempt out of 2.\n",
      "----------------------------------------\n",
      "-- Starting 'meryl' concurrent execution on Tue Nov 27 21:18:13 2018 with 2.186 GB free disk space (1 processes; 1 concurrently)\n",
      "\n",
      "    cd unitigging/0-mercounts\n",
      "    ./meryl-process.sh 1 > ./meryl-process.000001.out 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:27 2018 (14 seconds) with 2.193 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--\n",
      "--  22-mers                                                                                           Fraction\n",
      "--    Occurrences   NumMers                                                                         Unique Total\n",
      "--       1-     1         0                                                                        0.0000 0.0000\n",
      "--       2-     2    204079 ***********************************************************            0.3655 0.1377\n",
      "--       3-     4    239475 ********************************************************************** 0.6446 0.2955\n",
      "--       5-     7     62118 ******************                                                     0.8626 0.4725\n",
      "--       8-    11      5159 *                                                                      0.9096 0.5296\n",
      "--      12-    16      5388 *                                                                      0.9166 0.5432\n",
      "--      17-    22      8777 **                                                                     0.9272 0.5737\n",
      "--      23-    29      7369 **                                                                     0.9419 0.6292\n",
      "--      30-    37     21327 ******                                                                 0.9553 0.6970\n",
      "--      38-    46      4513 *                                                                      0.9955 0.9616\n",
      "--      47-    56        32                                                                        0.9998 0.9940\n",
      "--      57-    67         2                                                                        0.9999 0.9945\n",
      "--      68-    79         6                                                                        0.9999 0.9945\n",
      "--      80-    92         0                                                                        0.0000 0.0000\n",
      "--      93-   106         1                                                                        0.9999 0.9947\n",
      "--     107-   121         1                                                                        0.9999 0.9947\n",
      "--     122-   137         7                                                                        0.9999 0.9948\n",
      "--     138-   154         1                                                                        0.9999 0.9951\n",
      "--     155-   172         2                                                                        0.9999 0.9952\n",
      "--     173-   191         2                                                                        0.9999 0.9953\n",
      "--     192-   211         3                                                                        0.9999 0.9954\n",
      "--     212-   232         5                                                                        0.9999 0.9957\n",
      "--     233-   254         3                                                                        0.9999 0.9960\n",
      "--     255-   277        21                                                                        0.9999 0.9964\n",
      "--     278-   301        10                                                                        1.0000 0.9981\n",
      "--\n",
      "--           0 (max occurrences)\n",
      "--     2963512 (total mers, non-unique)\n",
      "--      558304 (distinct mers, non-unique)\n",
      "--           0 (unique mers)\n",
      "-- Finished stage 'meryl-process', reset canuIteration.\n",
      "--\n",
      "-- OVERLAPPER (normal) (assembly) erate=0.12\n",
      "--\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:27 2018 with 2.193 GB free disk space\n",
      "\n",
      "    cd unitigging/1-overlapper\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/overlapInCorePartition \\\n",
      "     -S  ../../sample.seqStore \\\n",
      "     -hl 80000000 \\\n",
      "     -rl 1000000000 \\\n",
      "     -ol 50 \\\n",
      "     -o  ./sample.partition \\\n",
      "    > ./sample.partition.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:27 2018 (like a bat out of hell) with 2.193 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--\n",
      "-- Configured 1 overlapInCore jobs.\n",
      "-- Finished stage 'utg-overlapConfigure', reset canuIteration.\n",
      "--\n",
      "-- Running jobs.  First attempt out of 2.\n",
      "----------------------------------------\n",
      "-- Starting 'utgovl' concurrent execution on Tue Nov 27 21:18:27 2018 with 2.193 GB free disk space (1 processes; 1 concurrently)\n",
      "\n",
      "    cd unitigging/1-overlapper\n",
      "    ./overlap.sh 1 > ./overlap.000001.out 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:44 2018 (17 seconds) with 2.193 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Found 1 overlapInCore output files.\n",
      "--\n",
      "-- overlapInCore compute 'unitigging/1-overlapper':\n",
      "--   kmer hits\n",
      "--     with no overlap             7184        7184 +- 0\n",
      "--     with an overlap            18247       18247 +- 0\n",
      "--\n",
      "--   overlaps                     18247       18247 +- 0\n",
      "--     contained                  10266       10266 +- 0\n",
      "--     dovetail                    7981        7981 +- 0\n",
      "--\n",
      "--   overlaps rejected\n",
      "--     multiple per pair              0           0 +- 0\n",
      "--     bad short window               0           0 +- 0\n",
      "--     bad long window                0           0 +- 0\n",
      "-- Finished stage 'utg-overlapCheck', reset canuIteration.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:44 2018 with 2.193 GB free disk space\n",
      "\n",
      "    cd unitigging\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/ovStoreConfig \\\n",
      "     -S ../sample.seqStore \\\n",
      "     -M 1 \\\n",
      "     -L ./1-overlapper/ovljob.files \\\n",
      "     -create ./sample.ovlStore.config \\\n",
      "     > ./sample.ovlStore.config.txt \\\n",
      "    2> ./sample.ovlStore.config.err\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:44 2018 (lickety-split) with 2.193 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--\n",
      "-- Creating overlap store unitigging/sample.ovlStore using:\n",
      "--      1 bucket\n",
      "--      2 slices\n",
      "--        using at most 1 GB memory each\n",
      "-- Finished stage 'utg-overlapStoreConfigure', reset canuIteration.\n",
      "--\n",
      "-- Running jobs.  First attempt out of 2.\n",
      "----------------------------------------\n",
      "-- Starting 'ovB' concurrent execution on Tue Nov 27 21:18:44 2018 with 2.193 GB free disk space (1 processes; 1 concurrently)\n",
      "\n",
      "    cd unitigging/sample.ovlStore.BUILDING\n",
      "    ./scripts/1-bucketize.sh 1 > ./logs/1-bucketize.000001.out 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:44 2018 (lickety-split) with 2.192 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Overlap store bucketizer finished.\n",
      "-- Finished stage 'utg-overlapStoreBucketizerCheck', reset canuIteration.\n",
      "--\n",
      "-- Running jobs.  First attempt out of 2.\n",
      "----------------------------------------\n",
      "-- Starting 'ovS' concurrent execution on Tue Nov 27 21:18:44 2018 with 2.192 GB free disk space (2 processes; 1 concurrently)\n",
      "\n",
      "    cd unitigging/sample.ovlStore.BUILDING\n",
      "    ./scripts/2-sort.sh 1 > ./logs/2-sort.000001.out 2>&1\n",
      "    ./scripts/2-sort.sh 2 > ./logs/2-sort.000002.out 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:45 2018 (one second) with 2.19 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Overlap store sorter finished.\n",
      "-- Finished stage 'utg-overlapStoreSorterCheck', reset canuIteration.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:45 2018 with 2.19 GB free disk space\n",
      "\n",
      "    cd unitigging\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/ovStoreIndexer \\\n",
      "      -O  ./sample.ovlStore.BUILDING \\\n",
      "      -S ../sample.seqStore \\\n",
      "      -C  ./sample.ovlStore.config \\\n",
      "      -delete \\\n",
      "    > ./sample.ovlStore.BUILDING.index.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:45 2018 (lickety-split) with 2.191 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Checking store.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:45 2018 with 2.191 GB free disk space\n",
      "\n",
      "    cd unitigging\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/ovStoreDump \\\n",
      "     -S ../sample.seqStore \\\n",
      "     -O  ./sample.ovlStore \\\n",
      "     -counts \\\n",
      "     > ./sample.ovlStore/counts.dat 2> ./sample.ovlStore/counts.err\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:45 2018 (fast as lightning) with 2.191 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--\n",
      "-- Overlap store 'unitigging/sample.ovlStore' successfully constructed.\n",
      "-- Found 36494 overlaps for 1391 reads; 2213 reads have no overlaps.\n",
      "--\n",
      "--\n",
      "-- Purged 0 GB in 3 overlap output files.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:45 2018 with 2.191 GB free disk space\n",
      "\n",
      "    cd unitigging\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/ovStoreStats \\\n",
      "     -C 1 \\\n",
      "     -S ../sample.seqStore \\\n",
      "     -O  ./sample.ovlStore \\\n",
      "     -o  ./sample.ovlStore \\\n",
      "     > ./sample.ovlStore.summary.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:45 2018 (furiously fast) with 2.191 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "--\n",
      "-- Overlap store 'unitigging/sample.ovlStore' contains:\n",
      "--\n",
      "--   category            reads     %          read length        feature size or coverage  analysis\n",
      "--   ----------------  -------  -------  ----------------------  ------------------------  --------------------\n",
      "--   middle-missing         23    1.51     1779.74 +- 2262.22        326.83 +- 513.75     (bad trimming)\n",
      "--   middle-hump            73    4.79     3070.22 +- 4336.97        138.41 +- 343.01     (bad trimming)\n",
      "--   no-5-prime             46    3.02     4615.09 +- 5701.23        100.28 +- 294.14     (bad trimming)\n",
      "--   no-3-prime             65    4.26     3637.86 +- 4195.84        190.65 +- 318.99     (bad trimming)\n",
      "--   \n",
      "--   low-coverage            0    0.00        0.00 +- 0.00             0.00 +- 0.00       (easy to assemble, potential for lower quality consensus)\n",
      "--   unique                 91    5.97      538.63 +- 673.32           1.00 +- 0.00       (easy to assemble, perfect, yay)\n",
      "--   repeat-cont           798   52.33     2827.94 +- 4482.75         21.87 +- 15.74      (potential for consensus errors, no impact on assembly)\n",
      "--   repeat-dove            26    1.70    10385.81 +- 11448.19        17.45 +- 14.79      (hard to assemble, likely won't assemble correctly or even at all)\n",
      "--   \n",
      "--   span-repeat            47    3.08     1885.53 +- 1429.47       1475.34 +- 1367.28    (read spans a large repeat, usually easy to assemble)\n",
      "--   uniq-repeat-cont      170   11.15     2275.69 +- 2732.62                             (should be uniquely placed, low potential for consensus errors, no impact on assembly)\n",
      "--   uniq-repeat-dove       14    0.92     4587.14 +- 4861.51                             (will end contigs, potential to misassemble)\n",
      "--   uniq-anchor            38    2.49     5786.63 +- 6977.12       1274.58 +- 2465.33    (repeat read, with unique section, probable bad read)\n",
      "-- Finished stage 'utg-createOverlapStore', reset canuIteration.\n",
      "--\n",
      "-- Loading read lengths.\n",
      "-- Loading number of overlaps per read.\n",
      "--\n",
      "-- Configure RED for 6gb memory.\n",
      "--                   Batches of at most (unlimited) reads.\n",
      "--                                      500000000 bases.\n",
      "--                   Expecting evidence of at most 536870912 bases per iteration.\n",
      "--\n",
      "--           Total                                               Reads                 Olaps Evidence\n",
      "--    Job   Memory      Read Range         Reads        Bases   Memory        Olaps   Memory   Memory  (Memory in MB)\n",
      "--   ---- -------- ------------------- --------- ------------ -------- ------------ -------- --------\n",
      "--      1  3119.20         1-3604           1525      4083553    46.78        36494     0.42  1024.00\n",
      "--   ---- -------- ------------------- --------- ------------ -------- ------------ -------- --------\n",
      "--                                                    4083553                 36494\n",
      "-- Finished stage 'readErrorDetectionConfigure', reset canuIteration.\n",
      "--\n",
      "-- Running jobs.  First attempt out of 2.\n",
      "----------------------------------------\n",
      "-- Starting 'red' concurrent execution on Tue Nov 27 21:18:45 2018 with 2.191 GB free disk space (1 processes; 1 concurrently)\n",
      "\n",
      "    cd unitigging/3-overlapErrorAdjustment\n",
      "    ./red.sh 1 > ./red.000001.out 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:47 2018 (2 seconds) with 2.191 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Found 1 read error detection output files.\n",
      "-- Finished stage 'readErrorDetectionCheck', reset canuIteration.\n",
      "--\n",
      "-- Loading read lengths.\n",
      "-- Loading number of overlaps per read.\n",
      "--\n",
      "-- Configure OEA for 4gb memory.\n",
      "--                   Batches of at most (unlimited) reads.\n",
      "--                                      300000000 bases.\n",
      "--\n",
      "--           Total                                               Reads                 Olaps  Adjusts\n",
      "--    Job   Memory      Read Range         Reads        Bases   Memory        Olaps   Memory   Memory  (Memory in MB)\n",
      "--   ---- -------- ------------------- --------- ------------ -------- ------------ -------- --------\n",
      "--      1  2381.43         1-3604           1525      4083553    11.94        36494     1.11   320.37\n",
      "--   ---- -------- ------------------- --------- ------------ -------- ------------ -------- --------\n",
      "--                                                    4083553                 36494\n",
      "-- Finished stage 'overlapErrorAdjustmentConfigure', reset canuIteration.\n",
      "--\n",
      "-- Running jobs.  First attempt out of 2.\n",
      "----------------------------------------\n",
      "-- Starting 'oea' concurrent execution on Tue Nov 27 21:18:47 2018 with 2.191 GB free disk space (1 processes; 1 concurrently)\n",
      "\n",
      "    cd unitigging/3-overlapErrorAdjustment\n",
      "    ./oea.sh 1 > ./oea.000001.out 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:49 2018 (2 seconds) with 2.191 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Found 1 overlap error adjustment output files.\n",
      "-- Finished stage 'overlapErrorAdjustmentCheck', reset canuIteration.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:49 2018 with 2.191 GB free disk space\n",
      "\n",
      "    cd unitigging/3-overlapErrorAdjustment\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/loadErates \\\n",
      "      -S ../../sample.seqStore \\\n",
      "      -O ../sample.ovlStore \\\n",
      "      -L ./oea.files \\\n",
      "    > ./oea.apply.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:49 2018 (in the blink of an eye) with 2.191 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- No report available.\n",
      "-- Finished stage 'updateOverlapStore', reset canuIteration.\n",
      "-- Finished stage 'unitig', reset canuIteration.\n",
      "--\n",
      "-- Running jobs.  First attempt out of 2.\n",
      "----------------------------------------\n",
      "-- Starting 'bat' concurrent execution on Tue Nov 27 21:18:49 2018 with 2.191 GB free disk space (1 processes; 1 concurrently)\n",
      "\n",
      "    cd unitigging/4-unitigger\n",
      "    ./unitigger.sh 1 > ./unitigger.000001.out 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:49 2018 (furiously fast) with 2.19 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Unitigger finished successfully.\n",
      "-- Found, in version 1, after unitig construction:\n",
      "--   contigs:      47 sequences, total length 353360 bp (including 0 repeats of total length 0 bp).\n",
      "--   bubbles:      0 sequences, total length 0 bp.\n",
      "--   unassembled:  973 sequences, total length 1723250 bp.\n",
      "--\n",
      "-- Contig sizes based on genome size 2.1mbp:\n",
      "--\n",
      "--            NG (bp)  LG (contigs)    sum (bp)\n",
      "--         ----------  ------------  ----------\n",
      "--     10       12546             9      216891\n",
      "--\n",
      "-- Finished stage 'unitigCheck', reset canuIteration.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:49 2018 with 2.19 GB free disk space\n",
      "\n",
      "    cd unitigging\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/sqStoreCreatePartition \\\n",
      "      -S ../sample.seqStore \\\n",
      "      -T  ./sample.ctgStore 1 \\\n",
      "      -b 15000 \\\n",
      "      -p 8 \\\n",
      "    > ./sample.ctgStore/partitionedReads.log 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:49 2018 (like a bat out of hell) with 2.185 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:49 2018 with 2.185 GB free disk space\n",
      "\n",
      "    cd unitigging\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/sqStoreCreatePartition \\\n",
      "      -S ../sample.seqStore \\\n",
      "      -T  ./sample.utgStore 1 \\\n",
      "      -b 15000 \\\n",
      "      -p 8 \\\n",
      "    > ./sample.utgStore/partitionedReads.log 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:49 2018 (furiously fast) with 2.183 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Using slow alignment for consensus (iteration '0').\n",
      "-- Configured 1 contig and 1 unitig consensus jobs.\n",
      "-- Finished stage 'consensusConfigure', reset canuIteration.\n",
      "--\n",
      "--                            (tag)Concurrency\n",
      "--                     (tag)Threads          |\n",
      "--            (tag)Memory         |          |\n",
      "--        (tag)         |         |          |     total usage     algorithm\n",
      "--        -------  ------  --------   --------  -----------------  -----------------------------\n",
      "-- Local: cns        1 GB    3 CPUs x   1 job      1 GB    3 CPUs  (consensus)\n",
      "--\n",
      "--\n",
      "-- Running jobs.  First attempt out of 2.\n",
      "----------------------------------------\n",
      "-- Starting 'cns' concurrent execution on Tue Nov 27 21:18:50 2018 with 2.183 GB free disk space (2 processes; 1 concurrently)\n",
      "\n",
      "    cd unitigging/5-consensus\n",
      "    ./consensus.sh 1 > ./consensus.000001.out 2>&1\n",
      "    ./consensus.sh 2 > ./consensus.000002.out 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:57 2018 (7 seconds) with 2.179 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Using slow alignment for consensus (iteration '1').\n",
      "-- Configured 1 contig and 1 unitig consensus jobs.\n",
      "-- All 2 consensus jobs finished successfully.\n",
      "-- Finished stage 'consensusCheck', reset canuIteration.\n",
      "-- Using slow alignment for consensus (iteration '0').\n",
      "-- Configured 1 contig and 1 unitig consensus jobs.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:57 2018 with 2.179 GB free disk space\n",
      "\n",
      "    cd unitigging\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/tgStoreLoad \\\n",
      "      -S ../sample.seqStore \\\n",
      "      -T  ./sample.ctgStore 2 \\\n",
      "      -L ./5-consensus/ctgcns.files \\\n",
      "    > ./5-consensus/ctgcns.files.ctgStoreLoad.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:57 2018 (furiously fast) with 2.175 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:57 2018 with 2.175 GB free disk space\n",
      "\n",
      "    cd unitigging\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/tgStoreLoad \\\n",
      "      -S ../sample.seqStore \\\n",
      "      -T  ./sample.utgStore 2 \\\n",
      "      -L ./5-consensus/utgcns.files \\\n",
      "    > ./5-consensus/utgcns.files.utgStoreLoad.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:57 2018 (in the blink of an eye) with 2.174 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Purging consensus output after loading to ctgStore and/or utgStore.\n",
      "-- Purged 2 .cns outputs.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:57 2018 with 2.185 GB free disk space\n",
      "\n",
      "    cd unitigging\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/tgStoreDump \\\n",
      "      -S ../sample.seqStore \\\n",
      "      -T ./sample.ctgStore 2 \\\n",
      "      -sizes -s 2100000 \\\n",
      "    > ./sample.ctgStore/seqDB.v002.sizes.txt\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:57 2018 (fast as lightning) with 2.185 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Found, in version 2, after consensus generation:\n",
      "--   contigs:      47 sequences, total length 351969 bp (including 0 repeats of total length 0 bp).\n",
      "--   bubbles:      0 sequences, total length 0 bp.\n",
      "--   unassembled:  973 sequences, total length 1722848 bp.\n",
      "--\n",
      "-- Contig sizes based on genome size 2.1mbp:\n",
      "--\n",
      "--            NG (bp)  LG (contigs)    sum (bp)\n",
      "--         ----------  ------------  ----------\n",
      "--     10       12478             9      216453\n",
      "--\n",
      "-- Finished stage 'consensusLoad', reset canuIteration.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:57 2018 with 2.185 GB free disk space\n",
      "\n",
      "    cd unitigging\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/tgStoreCoverageStat \\\n",
      "      -S ../sample.seqStore \\\n",
      "      -T  ./sample.ctgStore 2 \\\n",
      "      -s 2100000 \\\n",
      "      -o ./sample.ctgStore.coverageStat \\\n",
      "    > ./sample.ctgStore.coverageStat.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:57 2018 (like a bat out of hell) with 2.185 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Finished stage 'consensusAnalyze', reset canuIteration.\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:57 2018 with 2.185 GB free disk space\n",
      "\n",
      "    cd unitigging/4-unitigger\n",
      "    ./alignGFA.sh \\\n",
      "    > alignGFA.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:58 2018 (one second) with 2.185 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:58 2018 with 2.185 GB free disk space\n",
      "\n",
      "    cd .\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/tgStoreDump \\\n",
      "      -S ./sample.seqStore \\\n",
      "      -T ./unitigging/sample.ctgStore 2 \\\n",
      "      -o ./sample.contigs \\\n",
      "      -layout \\\n",
      "    > ./sample.contigs.layout.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:58 2018 (furiously fast) with 2.181 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:58 2018 with 2.181 GB free disk space\n",
      "\n",
      "    cd .\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/tgStoreDump \\\n",
      "      -S ./sample.seqStore \\\n",
      "      -T ./unitigging/sample.utgStore 2 \\\n",
      "      -o ./sample.unitigs \\\n",
      "      -layout \\\n",
      "    > ./sample.unitigs.layout.err 2>&1\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:58 2018 (fast as lightning) with 2.18 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:58 2018 with 2.18 GB free disk space\n",
      "\n",
      "    cd .\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/tgStoreDump \\\n",
      "      -S ./sample.seqStore \\\n",
      "      -T ./unitigging/sample.ctgStore 2 \\\n",
      "      -consensus -fasta \\\n",
      "      -unassembled \\\n",
      "    > ./sample.unassembled.fasta\n",
      "    2> ./sample.unassembled.err\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:58 2018 (in the blink of an eye) with 2.178 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:58 2018 with 2.178 GB free disk space\n",
      "\n",
      "    cd .\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/tgStoreDump \\\n",
      "      -S ./sample.seqStore \\\n",
      "      -T ./unitigging/sample.ctgStore 2 \\\n",
      "      -consensus -fasta \\\n",
      "      -contigs \\\n",
      "    > ./sample.contigs.fasta\n",
      "    2> ./sample.contigs.err\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:58 2018 (furiously fast) with 2.178 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "-- Starting command on Tue Nov 27 21:18:58 2018 with 2.178 GB free disk space\n",
      "\n",
      "    cd .\n",
      "    /home/jovyan/software/canu/Linux-amd64/bin/tgStoreDump \\\n",
      "      -S ./sample.seqStore \\\n",
      "      -T ./unitigging/sample.utgStore 2 \\\n",
      "      -consensus -fasta \\\n",
      "      -contigs \\\n",
      "    > ./sample.unitigs.fasta\n",
      "    2> ./sample.unitigs.err\n",
      "\n",
      "-- Finished on Tue Nov 27 21:18:58 2018 (like a bat out of hell) with 2.178 GB free disk space  !!! WARNING !!!\n",
      "----------------------------------------\n",
      "-- Finished stage 'generateOutputs', reset canuIteration.\n",
      "--\n",
      "-- Assembly 'sample' finished in '/home/jovyan/notebooks/data/sample/canu_output'.\n",
      "--\n",
      "-- Summary saved in 'sample.report'.\n",
      "--\n",
      "-- Sequences saved:\n",
      "--   Contigs       -> 'sample.contigs.fasta'\n",
      "--   Unassembled   -> 'sample.unassembled.fasta'\n",
      "--   Unitigs       -> 'sample.unitigs.fasta'\n",
      "--\n",
      "-- Read layouts saved:\n",
      "--   Contigs       -> 'sample.contigs.layout'.\n",
      "--   Unitigs       -> 'sample.unitigs.layout'.\n",
      "--\n",
      "-- Graphs saved:\n",
      "--   Contigs       -> 'sample.contigs.gfa'.\n",
      "--   Unitigs       -> 'sample.unitigs.gfa'.\n",
      "--\n",
      "-- Bye.\n"
     ]
    }
   ],
   "source": [
    "canu -p sample \\\n",
    "     -d data/sample/canu_output \\\n",
    "     genomeSize=2.1m \\\n",
    "     useGrid=false \\\n",
    "     minReadLength=50 \\\n",
    "     minOverlapLength=50 \\\n",
    "     corMemory=2 \\\n",
    "     corThreads=2 \\\n",
    "     maxMemory=6 \\\n",
    "     stopOnLowCoverage=1 \\\n",
    "     -nanopore-raw data/sample/reads.fastq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Racon\n",
    "\n",
    "[Racon](https://github.com/isovic/racon) is a consensus module to correct raw contigs generated by rapid assembly methods that do not include a consensus step. Canu results in FASTA format and raw reads in FASTQ are used in this step to generate a new FASTA contig file.\n",
    "\n",
    "Before running Racon, one must align the Canu output to the raw reads file and take the overlaps file in PAF as a parameter for Racon command. This can be done using for example minimap, a superfast aligner for ONT reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[M::mm_idx_gen::0.017*0.70] collected minimizers\n",
      "[M::mm_idx_gen::0.027*0.89] sorted minimizers\n",
      "[M::main::0.027*0.88] loaded/built the index for 47 target sequence(s)\n",
      "[M::mm_mapopt_update::0.030*0.80] mid_occ = 5\n",
      "[M::mm_idx_stat] kmer size: 15; skip: 10; is_hpc: 0; #seq: 47\n",
      "[M::mm_idx_stat::0.033*0.86] distinct minimizers: 61757 (93.56% are singletons); average occurrences: 1.067; average spacing: 5.340\n",
      "[M::worker_pipeline::0.533*2.25] mapped 3720 sequences\n",
      "[M::main] Version: 2.14-r890-dirty\n",
      "[M::main] CMD: minimap2 data/sample/canu_output/sample.contigs.fasta data/sample/reads.fastq\n",
      "[M::main] Real time: 0.536 sec; CPU: 1.200 sec; Peak RSS: 0.060 GB\n"
     ]
    }
   ],
   "source": [
    "minimap2 data/sample/canu_output/sample.contigs.fasta \\\n",
    "        data/sample/reads.fastq \\\n",
    "        > data/sample/aligned_reads.paf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic Racon parameters are the following:\n",
    "- **-t** : Number of threads\n",
    "- Raw reads (FASTQ)\n",
    "- Overlaps in (PAF)\n",
    "- Canu output (FASTA)\n",
    "- Racon output file name (FASTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[racon::Polisher::initialize] loaded target sequences\n",
      "[racon::Polisher::initialize] loaded sequences\n",
      "[racon::Polisher::initialize] loaded overlaps\n",
      "[racon::Polisher::initialize] aligned overlap 785/785\n",
      "[racon::Polisher::initialize] transformed data into windows\n",
      "[racon::Polisher::polish] generated consensus for window 726/726\n"
     ]
    }
   ],
   "source": [
    "mkdir -p data/sample/racon_output\n",
    "racon -t 48 \\\n",
    "     data/sample/reads.fastq \\\n",
    "     data/sample/aligned_reads.paf \\\n",
    "     data/sample/canu_output/sample.contigs.fasta > data/sample/racon_output/sample_racon.contigs.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pilon (Requires Illumina reads)\n",
    "\n",
    "[Pilon](https:github.com/broadinstitute/pilon) is a tool that can be used to improve a draft assembly and find variation among species or strains. Pilon maps the reads from Illumina read to an assembled sequence and corrects the errors of the base, and the small insertions and deletions (indels). It requires as input a FASTA file and a BAM file of reads aligned to the input FASTA file. At this point, it will need the Racon contigs file and the reads file (ONT and Illumina reads). The Racon contigs file and the BAM file produced by de alignment of Illumina reads against that contigs file generate the final result of Pilon.\n",
    "\n",
    "In first place, Illumina reads have to be aligned against the Racon contigs file. BWA is used to index the reference file (Racon contigs) and BWA-MEM is used to perform the alignment of the Illumina reads. In order to have the BAM file required by Pilon, SAMtools is used to convert the BWA output in FASTA to the BAM format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bwa_index] Pack FASTA... 0.00 sec\n",
      "[bwa_index] Construct BWT for the packed sequence...\n",
      "[bwa_index] 0.06 seconds elapse.\n",
      "[bwa_index] Update BWT... 0.00 sec\n",
      "[bwa_index] Pack forward-only FASTA... 0.00 sec\n",
      "[bwa_index] Construct SA from BWT and Occ... 0.03 sec\n",
      "[main] Version: 0.7.15-r1140\n",
      "[main] CMD: bwa index data/sample/racon_output/sample_racon.contigs.fasta\n",
      "[main] Real time: 0.130 sec; CPU: 0.096 sec\n"
     ]
    }
   ],
   "source": [
    "bwa index data/sample/racon_output/sample_racon.contigs.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mkdir -p data/sample/bwa_output\n",
    "#Data not included in repository\n",
    "bwa mem -t 2 \\\n",
    "        data/sample/racon_output/sample_racon.contigs.fasta  \\\n",
    "        data/sample/short/reads_1.fastq.gz \\\n",
    "        data/sample/short/reads_2.fastq.gz \\\n",
    "        | samtools view -S -b -u - | samtools sort - data/sample/bwa_output/bwa_aligned_reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running Pilon, the BWA alignment is indexed using SAMtools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samtools index data/sample/bwa_output/bwa_aligned_reads.bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pilon is run as a Java .jar executable. Some options can be added to improve the performance of Pilon before specifying the .jar file. Whichever the case, Pilon works better in terms of execution time when it is run on an environment with more available RAM and threads. The parameters used in this Pilon run are the following:\n",
    "\n",
    "- **--threads**: Number of threads\n",
    "- **--genome**: The FASTA input file (Racon contigs)\n",
    "- **--bam**: BAM file (generated by BWA and SAMtools)\n",
    "- **--outdir** and **--output**: Output directory and filename "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "java -Xmx128g -XX:+UseConcMarkSweepGC \\ \n",
    "      -XX:-UseGCOverheadLimit \\ \n",
    "      -jar /home/jovyan/software/pilon/pilon-1.22.jar \\ \n",
    "      --threads 2 \\ \n",
    "      --genome  data/sample/racon_output/sample_racon.contigs.fasta \\ \n",
    "      --bam data/sample/bwa_output/bwa_aligned_reads.bam \\ \n",
    "      --outdir data/sample/pilon_output \\ \n",
    "      --output pilon.contigs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *De novo* Miniasm assembly\n",
    " \n",
    "[Miniasm](https://github.com/lh3/miniasm) is a fast Overlap-Layout-Consensus-based option for *de novo* assembly of noisy long reads. Miniasm builds high-confidence contigs (unitigs) concatenating pieces of read sequences. It takes all read self-mappings as input to output an assembly graph. At least for high-coverage bacterial genomes, Miniasm can generate long contigs from raw ONT reads without error correction. The error rate of the assembly is the same as that of the raw input reads. In this way, Miniasm produces uncontaminated and uncorrected contig sequences from raw read overlays. To reduce the presence of artefacts such as adapters and untrimmed chimeras in the assembly, Miniasm calculates the per base coverage based on good mappings (longer than 2 kb with at least 100 bp non-redundant bases on matching minimizers) versus other reads. \n",
    "Furthermore, Miniasm ignores internal matches, eliminates contained reads, and adds overlays to the assembly graph. To avoid multiple edges, Miniasm uses the longest overlay. When the assembly graph is generated, it removes the transitive edges, trims the tilt units composed of few reads, and permits small bubbles to appear. \n",
    "\n",
    "Although it cannot produce a high-quality consensus, Miniasm is extremely fast and produces continuous and structurally accurate assemblies, at least for genomes without excessive repetitive sequences. \n",
    "\n",
    "Minimap is first used to get an all-vs-all read mappings of the reads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[M::mm_idx_gen::0.936*0.99] collected minimizers\n",
      "[M::mm_idx_gen::1.112*1.24] sorted minimizers\n",
      "[M::main::1.112*1.24] loaded/built the index for 3720 target sequence(s)\n",
      "[M::mm_mapopt_update::1.185*1.22] mid_occ = 24\n",
      "[M::mm_idx_stat] kmer size: 15; skip: 10; is_hpc: 0; #seq: 3720\n",
      "[M::mm_idx_stat::1.249*1.20] distinct minimizers: 5490363 (89.07% are singletons); average occurrences: 1.187; average spacing: 5.345\n",
      "[M::worker_pipeline::3.369*2.07] mapped 3720 sequences\n",
      "[M::main] Version: 2.14-r890-dirty\n",
      "[M::main] CMD: minimap2 data/sample/reads.fastq data/sample/reads.fastq\n",
      "[M::main] Real time: 3.391 sec; CPU: 6.988 sec; Peak RSS: 0.288 GB\n"
     ]
    }
   ],
   "source": [
    "minimap2  data/sample/reads.fastq data/sample/reads.fastq | gzip -1 > data/sample/reads.paf.gz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miniasm takes the obtained mappings file and the FASTA reads file and generates the final assembly. The assembly algorithm doesn't have a consensus step as it usually needs multiple steps to produce a precise consensus sequence, and that is a computational bottleneck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[M::main] ===> Step 1: reading read mappings <===\n",
      "[M::ma_hit_read::0.005*0.75] read 3600 hits; stored 2189 hits and 2189 sequences (33596139 bp)\n",
      "[M::main] ===> Step 2: 1-pass (crude) read selection <===\n",
      "[M::ma_hit_sub::0.006*0.72] 0 query sequences remain after sub\n",
      "[M::ma_hit_cut::0.006*0.72] 0 hits remain after cut\n",
      "[M::ma_hit_flt::0.006*0.72] 0 hits remain after filtering; crude coverage after filtering: -nan\n",
      "[M::main] ===> Step 3: 2-pass (fine) read selection <===\n",
      "[M::ma_hit_sub::0.006*0.72] 0 query sequences remain after sub\n",
      "[M::ma_hit_cut::0.006*0.72] 0 hits remain after cut\n",
      "[M::ma_hit_contained::0.006*0.71] 0 sequences and 0 hits remain after containment removal\n",
      "[M::main] ===> Step 4: graph cleaning <===\n",
      "[M::ma_sg_gen] read 0 arcs\n",
      "[M::main] ===> Step 4.1: transitive reduction <===\n",
      "[M::asg_arc_del_trans] transitively reduced 0 arcs\n",
      "[M::main] ===> Step 4.2: initial tip cutting and bubble popping <===\n",
      "[M::asg_cut_tip] cut 0 tips\n",
      "[M::asg_arc_del_multi] removed 0 multi-arcs\n",
      "[M::asg_arc_del_asymm] removed 0 asymmetric arcs\n",
      "[M::asg_pop_bubble] popped 0 bubbles and trimmed 0 tips\n",
      "[M::main] ===> Step 4.3: cutting short overlaps (3 rounds in total) <===\n",
      "[M::asg_arc_del_short] removed 0 short overlaps\n",
      "[M::asg_arc_del_short] removed 0 short overlaps\n",
      "[M::asg_arc_del_short] removed 0 short overlaps\n",
      "[M::main] ===> Step 4.4: removing short internal sequences and bi-loops <===\n",
      "[M::asg_cut_internal] cut 0 internal sequences\n",
      "[M::asg_cut_biloop] cut 0 small bi-loops\n",
      "[M::asg_cut_tip] cut 0 tips\n",
      "[M::asg_pop_bubble] popped 0 bubbles and trimmed 0 tips\n",
      "[M::main] ===> Step 4.5: aggressively cutting short overlaps <===\n",
      "[M::asg_arc_del_short] removed 0 short overlaps\n",
      "[M::main] ===> Step 5: generating unitigs <===\n",
      "[M::main] Version: 0.3-r179\n",
      "[M::main] CMD: miniasm -f data/sample/reads.fastq data/sample/reads.paf.gz\n",
      "[M::main] Real time: 0.087 sec; CPU: 0.064 sec\n"
     ]
    }
   ],
   "source": [
    "miniasm -f data/sample/reads.fastq data/sample/reads.paf.gz  > data/sample/miniasm_assembly.fasta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] Loman N.J., Quick J. and Simpson J.T. A complete bacterial genome assembled de novo using only nanopore sequencing data. Nature Methods 2015 12:733–735. DOI https://doi.org/10.1101/015552\n",
    "\n",
    "[2] Li H. Minimap and miniasm: fast mapping and de novo assembly for noisy long sequences. Bioinformatics, Volume 32, Issue 14, 15 July 2016, Pages 2103–2110. DOI https://doi.org/10.1093/bioinformatics/btw152"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
